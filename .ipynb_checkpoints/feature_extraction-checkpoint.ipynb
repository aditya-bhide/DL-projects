{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZQ47g0UvqMb_"
   },
   "source": [
    "# Feature Extraction\n",
    "Convolutional Neural Networks can also be use just for extracting specific features from the dataset. Lets take an example of Dog vs Cat image dataset. Now using CNN we can extract the features from the images and then use any classification algorithm to classify the images. We will be using Support Vector Machine. Here extracted features will act as columns. The features extraction flow is as follows:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OiqtgAi9rRbf"
   },
   "source": [
    "First we have to get the dataset from kaggle so get your own `kaggle.json` and run next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "Yb9nVtbrFaLJ",
    "outputId": "017a6071-6c80-4e51-be29-dfaf13b432aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
      "Downloading train.zip to /content\n",
      " 99% 540M/543M [00:04<00:00, 134MB/s]\n",
      "100% 543M/543M [00:04<00:00, 129MB/s]\n",
      "Downloading test1.zip to /content\n",
      " 98% 265M/271M [00:02<00:00, 108MB/s] \n",
      "100% 271M/271M [00:02<00:00, 99.1MB/s]\n",
      "Downloading sampleSubmission.csv to /content\n",
      "  0% 0.00/86.8k [00:00<?, ?B/s]\n",
      "100% 86.8k/86.8k [00:00<00:00, 91.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle competitions download -c dogs-vs-cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CTtdETO7rf2U"
   },
   "source": [
    "#### Extract the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "x4d77Ys3yqaU",
    "outputId": "801d4c62-3feb-492d-8820-b6b95cc2eb01"
   },
   "outputs": [],
   "source": [
    "!unzip -q test1.zip\n",
    "!unzip -q train.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PvFhvHaWrkxZ"
   },
   "source": [
    "Store images in such a way that it will be easier to pass them to `dataset.ImageFolder`. It requires all images in the folders based on their labels so we will require subfolders 'dog' and 'cat' in the main 'train' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O8XDVErdUjUr"
   },
   "outputs": [],
   "source": [
    "!cd train && mkdir dog cat\n",
    "!cd test1 && mkdir dog cat\n",
    "!mv train/dog.* train/dog\n",
    "!mv train/cat.* train/cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RIVzfABTuHaH"
   },
   "source": [
    "#### Import Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OLvedQFyDj56"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import svm\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CqUTDD-WEMkd"
   },
   "outputs": [],
   "source": [
    "# select cuda device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O2ilBhVkGMEv"
   },
   "outputs": [],
   "source": [
    "# Apply following transformation on the dataset.\n",
    "# ResNet is used so images should be in (244,244) format \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(244),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0,), (0.50,)),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root='train', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CN1qXk4SKI4"
   },
   "outputs": [],
   "source": [
    "split_ratio = 0.8\n",
    "data_len = len(dataset)\n",
    "train_size = int(split_ratio * data_len)\n",
    "test_size = data_len - train_size\n",
    "\n",
    "# Randomly splits data into given sizes\n",
    "train_dataset, test_dataset = random_split(dataset, lengths=(train_size, test_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n-9pcxcwu0yL"
   },
   "source": [
    "`datasets.ImageFolder` stores images in tuple format. Each position in the tuple has 2 elements first is the preprocessed image and second is the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 854
    },
    "colab_type": "code",
    "id": "KBLpnuCOSZru",
    "outputId": "8d27500d-5cb4-4fe4-8c44-03bb111af6bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.2980, 0.2745, 0.2745,  ..., 0.4627, 0.4784, 0.4706],\n",
      "         [0.2824, 0.2588, 0.2667,  ..., 0.4706, 0.4863, 0.4784],\n",
      "         [0.2667, 0.2588, 0.2588,  ..., 0.4706, 0.4784, 0.4706],\n",
      "         ...,\n",
      "         [1.0431, 1.0431, 1.0431,  ..., 0.6667, 0.5412, 0.5490],\n",
      "         [1.0667, 1.1059, 1.1608,  ..., 0.7529, 0.6745, 0.5647],\n",
      "         [1.1608, 1.1922, 1.1686,  ..., 0.6275, 0.7294, 0.7294]],\n",
      "\n",
      "        [[0.2431, 0.2588, 0.2745,  ..., 0.4706, 0.4863, 0.4784],\n",
      "         [0.2353, 0.2431, 0.2667,  ..., 0.4784, 0.4941, 0.4863],\n",
      "         [0.2431, 0.2431, 0.2510,  ..., 0.4784, 0.4863, 0.4784],\n",
      "         ...,\n",
      "         [0.6039, 0.5647, 0.5569,  ..., 0.6667, 0.5412, 0.5490],\n",
      "         [0.6667, 0.6039, 0.6353,  ..., 0.7529, 0.6745, 0.5647],\n",
      "         [0.7608, 0.7137, 0.6824,  ..., 0.6196, 0.7294, 0.7294]],\n",
      "\n",
      "        [[0.2980, 0.2824, 0.2902,  ..., 0.5098, 0.5255, 0.5176],\n",
      "         [0.2745, 0.2745, 0.2824,  ..., 0.5176, 0.5333, 0.5255],\n",
      "         [0.2431, 0.2588, 0.2745,  ..., 0.5176, 0.5255, 0.5176],\n",
      "         ...,\n",
      "         [0.4078, 0.3216, 0.3059,  ..., 0.7294, 0.6039, 0.6118],\n",
      "         [0.5020, 0.4235, 0.4392,  ..., 0.8392, 0.7529, 0.6353],\n",
      "         [0.5882, 0.5255, 0.5020,  ..., 0.7294, 0.8314, 0.8157]]]), 0)\n",
      "(tensor([[[0.2275, 0.2118, 0.2039,  ..., 0.5804, 0.5176, 0.3843],\n",
      "         [0.2510, 0.2353, 0.2118,  ..., 0.6039, 0.5412, 0.3686],\n",
      "         [0.2745, 0.2588, 0.2353,  ..., 0.5961, 0.5412, 0.3686],\n",
      "         ...,\n",
      "         [1.5922, 1.5922, 1.5922,  ..., 1.4353, 1.4510, 1.4667],\n",
      "         [1.5843, 1.5843, 1.5843,  ..., 1.4353, 1.4510, 1.4667],\n",
      "         [1.5843, 1.5843, 1.5843,  ..., 1.4275, 1.4353, 1.4510]],\n",
      "\n",
      "        [[0.3451, 0.3294, 0.3216,  ..., 0.5961, 0.5490, 0.4235],\n",
      "         [0.3137, 0.2980, 0.2745,  ..., 0.6118, 0.5725, 0.4078],\n",
      "         [0.2902, 0.2745, 0.2510,  ..., 0.6118, 0.5647, 0.4078],\n",
      "         ...,\n",
      "         [1.6627, 1.6627, 1.6627,  ..., 1.6549, 1.6706, 1.6863],\n",
      "         [1.6549, 1.6549, 1.6549,  ..., 1.6549, 1.6706, 1.6863],\n",
      "         [1.6549, 1.6549, 1.6549,  ..., 1.6471, 1.6549, 1.6706]],\n",
      "\n",
      "        [[0.3294, 0.3059, 0.3059,  ..., 0.6353, 0.5882, 0.4549],\n",
      "         [0.3137, 0.2980, 0.2745,  ..., 0.6510, 0.6118, 0.4392],\n",
      "         [0.3059, 0.2824, 0.2588,  ..., 0.6510, 0.6039, 0.4392],\n",
      "         ...,\n",
      "         [1.6549, 1.6549, 1.6549,  ..., 1.9608, 1.9765, 1.9922],\n",
      "         [1.6471, 1.6471, 1.6471,  ..., 1.9686, 1.9765, 1.9922],\n",
      "         [1.6471, 1.6471, 1.6471,  ..., 1.9608, 1.9686, 1.9765]]]), 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0])\n",
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8zf1Z0AISMR-"
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yaGPoBasGMqO"
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4d-rtCHNxwj0"
   },
   "source": [
    "Initializing pretrained ResNet Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "5XL4XN12GMtn",
    "outputId": "199e69b0-27dc-44ba-df21-34d58eb98922"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n",
      "100%|██████████| 97.8M/97.8M [00:02<00:00, 45.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "model_rsn_pre = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WPT1vDN-GNEO",
    "outputId": "6af5d6fb-e8de-43c6-9c49-49ecb20373b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rsn_pre.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ozJUsOr7x5kJ"
   },
   "source": [
    "Now we just want the features extracted from the image. The ResNet pretrained model is trained on Imagenet dataset. So its last layer has 1000 nodes for 1000 classes so we will take the output of second last layer to get features extracted from the image. Second last layer is a pooling layer so we have to flatten its three dimensional output before passing it to SVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lP9zy1p_IO3e"
   },
   "outputs": [],
   "source": [
    "# Function to get the ooutput of secong last layer\n",
    "def pooling_output(x):\n",
    "    global model_rsn_pre\n",
    "    for layer_name, layer in model_rsn_pre._modules.items():\n",
    "        x = layer(x)\n",
    "        if layer_name == 'avgpool':\n",
    "            break\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GSNph6LrGM_u"
   },
   "outputs": [],
   "source": [
    "# Returns the features and their corresponding labels \n",
    "def feature_extractor(dataloader):\n",
    "    labels = []\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        model_rsn_pre.eval()\n",
    "        for inputs, label in dataloader:\n",
    "            result = pooling_output(inputs.to(device))\n",
    "            features.append(result.cpu().view(1, -1))\n",
    "            labels.append(label)\n",
    "            torch.cuda.empty_cache()\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tv42Sr2nGM9r"
   },
   "outputs": [],
   "source": [
    "# extract features from train data\n",
    "train_features, train_labels = feature_extractor(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6c30RGKGM6o"
   },
   "outputs": [],
   "source": [
    "# extract features from test data\n",
    "test_features, test_labels = feature_extractor(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRrmaQ0A0LgI"
   },
   "source": [
    "Now extracted features have one extra dimension so use `torch.stack` and then `tensor.squeeze`to manage its dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PsoONPPertNF"
   },
   "outputs": [],
   "source": [
    "train_features = torch.stack(train_features)\n",
    "train_labels = torch.stack(train_labels)\n",
    "test_features = torch.stack(test_features)\n",
    "test_labels = torch.stack(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XglVhTxK8oIT"
   },
   "outputs": [],
   "source": [
    "train_features = train_features.squeeze()\n",
    "train_labels = train_labels.squeeze()\n",
    "test_features = test_features.squeeze()\n",
    "test_labels = test_labels.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGtJd1RY0rPw"
   },
   "source": [
    "`sklearn` requires the inputs in numpy format so convert everything to numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zqPV_rHlTy20"
   },
   "outputs": [],
   "source": [
    "train_features = train_features.numpy()\n",
    "train_labels = train_labels.numpy()\n",
    "test_features = test_features.numpy()\n",
    "test_labels = test_labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FAKTc-E4Y7bu"
   },
   "outputs": [],
   "source": [
    "# reshape numpy array in the format that is required by SVM \n",
    "train_features = train_features.reshape(len(train_features), 2048,)\n",
    "train_labels = train_labels.reshape(len(train_labels),)\n",
    "test_features = test_features.reshape(len(test_features), 2048,)\n",
    "test_labels = test_labels.reshape(len(test_labels),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "4O9NIF8w-avg",
    "outputId": "40ca79c7-5cb8-4ca9-b76b-c8aa5806394b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 2048)\n",
      "(20000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RIpW1X8l1EAS"
   },
   "source": [
    "#### Defining the SVM model\n",
    "Here `BaggingClassifier` is used over SVM to increase it's speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "8hz-XrP4BbvA",
    "outputId": "14f4721f-4f59-404e-a41c-eec771cec7ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                           fit_intercept=True,\n",
       "                                           intercept_scaling=1,\n",
       "                                           loss='squared_hinge',\n",
       "                                           max_iter=1000000, multi_class='ovr',\n",
       "                                           penalty='l2', random_state=42,\n",
       "                                           tol=0.0001, verbose=True),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                  max_samples=0.1, n_estimators=10, n_jobs=None,\n",
       "                  oob_score=False, random_state=None, verbose=0,\n",
       "                  warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = 10 \n",
    "clf = BaggingClassifier(svm.LinearSVC(random_state=42, verbose=True, max_iter=1000000), max_samples=1.0 / n_estimators, n_estimators=n_estimators)\n",
    "clf.fit(train_features,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "owzjGWCDGM1V"
   },
   "outputs": [],
   "source": [
    "test_pred = clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Q_5jc3GiNrim",
    "outputId": "d8d918fd-89bc-49e6-c565-a8ab57177130"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pwjz_KjU1fPY"
   },
   "source": [
    "The confusion matrix and accuracy on the testing dataset containing 5000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "ErTkYhxYGMoK",
    "outputId": "667321cb-9ebb-4563-a91d-d1fc9942f7db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2475   26]\n",
      " [  29 2470]]\n",
      "0.989\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(test_labels, test_pred))\n",
    "print(metrics.accuracy_score(test_labels, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HWH88M3bZpD9"
   },
   "source": [
    "### Classification without feature exctraction\n",
    "In this case we will directly pass the image to SVM model without using CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mP54d1rld_DL"
   },
   "outputs": [],
   "source": [
    "# Defining transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(244),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0,), (0.50,)),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root='train', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "joDxcrEod_Da"
   },
   "outputs": [],
   "source": [
    "split_ratio = 0.8\n",
    "data_len = len(dataset)\n",
    "train_size = int(split_ratio * data_len)\n",
    "test_size = data_len - train_size\n",
    "\n",
    "# Randomly splits data into given sizes\n",
    "train_dataset, test_dataset = random_split(dataset, lengths=(train_size, test_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ywg8wNLsECWu"
   },
   "source": [
    "Previously the size of extracted features was 2048 but now we are directly passing the original image to the SVM so the input image size after flattening is going to be 59536. The system will run out of RAM if we try to create a variabel containig 20000 images of that size so we will divide the dataset into batched of size 1000 and train our model on each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GaNvZSt5dYJ0"
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_dataset, batch_size=1000)\n",
    "testloader = DataLoader(test_dataset, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "id": "7o5MkC07dYH6",
    "outputId": "107c00e6-480c-4e0c-d5e3-f5ff83ba62a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0\n",
      "Batch: 1\n",
      "Batch: 2\n",
      "Batch: 3\n",
      "Batch: 4\n",
      "Batch: 5\n",
      "Batch: 6\n",
      "Batch: 7\n",
      "Batch: 8\n",
      "Batch: 9\n",
      "Batch: 10\n",
      "Batch: 11\n",
      "Batch: 12\n",
      "Batch: 13\n",
      "Batch: 14\n",
      "Batch: 15\n",
      "Batch: 16\n",
      "Batch: 17\n",
      "Batch: 18\n",
      "Batch: 19\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 10\n",
    "clf = BaggingClassifier(svm.LinearSVC(random_state=42, max_iter=1000000), max_samples=1.0 / n_estimators, n_estimators=n_estimators)\n",
    "\n",
    "# Training over 1000 images per batch\n",
    "i = 0\n",
    "for x, y, in trainloader:\n",
    "    x = x.view(x.shape[0], -1).numpy()\n",
    "    y = y.numpy()\n",
    "    clf.fit(x, y)\n",
    "    print(\"Batch:\", i)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SMk09N_CTVMZ"
   },
   "outputs": [],
   "source": [
    "labels = np.array([])\n",
    "predictions = np.array([])\n",
    "# Testing in the batch of 1000\n",
    "for x, y, in testloader:\n",
    "    x = x.view(x.shape[0], -1).numpy()\n",
    "    # print(x.shape)\n",
    "    y = y.numpy()\n",
    "    # print(y.shape)\n",
    "    a = clf.predict(x)\n",
    "    predictions = np.concatenate((predictions, a), axis=0)\n",
    "    labels = np.concatenate((labels, y), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-EuCnaOodYFn",
    "outputId": "edc68758-25f7-4d88-957b-989d97519ca5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "t8z-Vo97dYDN",
    "outputId": "6897a9ef-b1d2-479f-97af-263c67c3354c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1683  782]\n",
      " [1602  933]]\n",
      "0.5232\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(labels, predictions))\n",
    "print(metrics.accuracy_score(labels, predictions))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of feature_extraction.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
